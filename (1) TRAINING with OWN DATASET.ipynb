{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3c40c7cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#IMPORTING LIBRARIES\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import tensorflow as tf\n",
    "from PIL import Image\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import Dense, Flatten, Dropout\n",
    "from keras.layers.convolutional import Convolution2D as Conv2D, MaxPooling2D as MaxPool2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "93595277",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "labels = []\n",
    "classes = 5\n",
    "cur_path = os.getcwd()\n",
    "\n",
    "#there are 43 kinds of traffic sign boards in the dataset, hence the no. of of classes is taken as 43.\n",
    "#Retrieving the images and their labels\n",
    "for i in range(classes):\n",
    "    path = os.path.join(cur_path,'train_own',str(i+1))\n",
    "    images = os.listdir(path)\n",
    "\n",
    "    #we open each folder and extract the images and store in the list data[]\n",
    "    for a in images:\n",
    "        try:\n",
    "            image = Image.open(path + '\\\\'+ a)\n",
    "            image = image.resize((30,30))\n",
    "            image = np.array(image)\n",
    "            #sim = Image.fromarray(image)\n",
    "            data.append(image)\n",
    "            labels.append(i+1)\n",
    "        except:\n",
    "            print(\"Error loading image\")\n",
    "\n",
    "#Converting lists into numpy arrays\n",
    "#We need to convert the list into numpy arrays for feeding to the model.\n",
    "data = np.array(data)\n",
    "labels = np.array(labels)\n",
    "\n",
    "# we have stored all the images and their labels into lists (data and labels).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0462f704",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(99, 30, 30, 3) (99,)\n",
      "(79, 30, 30, 3) (20, 30, 30, 3) (79,) (20,)\n"
     ]
    }
   ],
   "source": [
    "print(data.shape, labels.shape)\n",
    "#Splitting training and testing dataset\n",
    "#random_state indicates the highest number of the folder\n",
    "X_train, X_test, y_train, y_test = train_test_split(data, labels, test_size=0.2, random_state=5)\n",
    "\n",
    "print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)\n",
    "\n",
    "#Converting the labels into one hot encoding\n",
    "y_train = to_categorical(y_train,6)\n",
    "y_test = to_categorical(y_test,6)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4355cf2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_8 (Conv2D)           (None, 26, 26, 32)        2432      \n",
      "                                                                 \n",
      " conv2d_9 (Conv2D)           (None, 22, 22, 32)        25632     \n",
      "                                                                 \n",
      " max_pooling2d_4 (MaxPooling  (None, 11, 11, 32)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " dropout_6 (Dropout)         (None, 11, 11, 32)        0         \n",
      "                                                                 \n",
      " conv2d_10 (Conv2D)          (None, 9, 9, 64)          18496     \n",
      "                                                                 \n",
      " conv2d_11 (Conv2D)          (None, 7, 7, 64)          36928     \n",
      "                                                                 \n",
      " max_pooling2d_5 (MaxPooling  (None, 3, 3, 64)         0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " dropout_7 (Dropout)         (None, 3, 3, 64)          0         \n",
      "                                                                 \n",
      " flatten_2 (Flatten)         (None, 576)               0         \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 256)               147712    \n",
      "                                                                 \n",
      " dropout_8 (Dropout)         (None, 256)               0         \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 6)                 1542      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 232,742\n",
      "Trainable params: 232,742\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#Building the model\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(filters=32, kernel_size=(5,5), activation='relu', input_shape=X_train.shape[1:]))\n",
    "model.add(Conv2D(filters=32, kernel_size=(5,5), activation='relu'))\n",
    "#we first add two 2-D convolutional layers to the model with 32 filters each\n",
    "#kernel size is 5*5 which will move around the image to get features.\n",
    "#activation function used is rectified linear (ReLu) fuction.\n",
    "\n",
    "model.add(MaxPool2D(pool_size=(2, 2)))\n",
    "#then we do max pooling, to reduce the amount of parameters and computation in the network.\n",
    "\n",
    "model.add(Dropout(rate=0.25))\n",
    "#Dropout is a technique where randomly selected neurons are ignored during training to prevent overfitting\n",
    "\n",
    "model.add(Conv2D(filters=64, kernel_size=(3, 3), activation='relu'))\n",
    "model.add(Conv2D(filters=64, kernel_size=(3, 3), activation='relu'))\n",
    "model.add(MaxPool2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(rate=0.25))\n",
    "#now again two convolutional layers with 64 filters each and 3*3 kernel size are added  and maxpooling, dropout is done\n",
    "\n",
    "model.add(Flatten())\n",
    "#a flattening layer is used to convert data/image into 1-D array\n",
    "\n",
    "model.add(Dense(256, activation='relu'))\n",
    "#a dense layer is added,for being fully connected to the previous layer\n",
    "\n",
    "model.add(Dropout(rate=0.5))\n",
    "#dropout layer added to avoid overfitting\n",
    "\n",
    "model.add(Dense(6, activation='softmax'))\n",
    "#a softmax layer is added to convert an array of numbers into array of probabilities of occurence of a feature\n",
    "\n",
    "#Compilation of the model\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "#loss is “categorical_crossentropy” because we have multiple classes to categorise.\n",
    "#metrics is chosen to be accuracy, because we wish to optimise it\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ea3470bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      "3/3 [==============================] - 0s 91ms/step - loss: 1.2277 - accuracy: 0.4557 - val_loss: 1.2714 - val_accuracy: 0.5500\n",
      "Epoch 2/40\n",
      "3/3 [==============================] - 0s 73ms/step - loss: 1.0287 - accuracy: 0.6709 - val_loss: 1.4188 - val_accuracy: 0.4500\n",
      "Epoch 3/40\n",
      "3/3 [==============================] - 0s 76ms/step - loss: 0.8921 - accuracy: 0.6203 - val_loss: 1.1916 - val_accuracy: 0.5500\n",
      "Epoch 4/40\n",
      "3/3 [==============================] - 0s 72ms/step - loss: 0.7828 - accuracy: 0.7089 - val_loss: 1.0160 - val_accuracy: 0.6500\n",
      "Epoch 5/40\n",
      "3/3 [==============================] - 0s 76ms/step - loss: 0.9620 - accuracy: 0.5949 - val_loss: 1.0776 - val_accuracy: 0.5000\n",
      "Epoch 6/40\n",
      "3/3 [==============================] - 0s 71ms/step - loss: 0.7347 - accuracy: 0.7468 - val_loss: 1.1192 - val_accuracy: 0.5000\n",
      "Epoch 7/40\n",
      "3/3 [==============================] - 0s 75ms/step - loss: 0.7840 - accuracy: 0.6709 - val_loss: 1.0318 - val_accuracy: 0.5500\n",
      "Epoch 8/40\n",
      "3/3 [==============================] - 0s 86ms/step - loss: 0.7941 - accuracy: 0.6962 - val_loss: 0.9107 - val_accuracy: 0.6000\n",
      "Epoch 9/40\n",
      "3/3 [==============================] - 0s 77ms/step - loss: 0.6517 - accuracy: 0.7595 - val_loss: 0.9130 - val_accuracy: 0.7000\n",
      "Epoch 10/40\n",
      "3/3 [==============================] - 0s 82ms/step - loss: 0.6771 - accuracy: 0.8101 - val_loss: 1.0017 - val_accuracy: 0.5500\n",
      "Epoch 11/40\n",
      "3/3 [==============================] - 0s 83ms/step - loss: 0.6432 - accuracy: 0.7468 - val_loss: 1.0628 - val_accuracy: 0.5000\n",
      "Epoch 12/40\n",
      "3/3 [==============================] - 0s 86ms/step - loss: 0.6704 - accuracy: 0.7342 - val_loss: 0.9167 - val_accuracy: 0.6500\n",
      "Epoch 13/40\n",
      "3/3 [==============================] - 0s 85ms/step - loss: 0.4876 - accuracy: 0.8354 - val_loss: 0.8965 - val_accuracy: 0.6500\n",
      "Epoch 14/40\n",
      "3/3 [==============================] - 0s 83ms/step - loss: 0.5301 - accuracy: 0.8101 - val_loss: 0.9642 - val_accuracy: 0.7000\n",
      "Epoch 15/40\n",
      "3/3 [==============================] - 0s 81ms/step - loss: 0.4752 - accuracy: 0.8228 - val_loss: 0.8521 - val_accuracy: 0.7000\n",
      "Epoch 16/40\n",
      "3/3 [==============================] - 0s 86ms/step - loss: 0.4355 - accuracy: 0.8608 - val_loss: 0.8772 - val_accuracy: 0.6500\n",
      "Epoch 17/40\n",
      "3/3 [==============================] - 0s 80ms/step - loss: 0.4494 - accuracy: 0.8861 - val_loss: 0.9213 - val_accuracy: 0.7000\n",
      "Epoch 18/40\n",
      "3/3 [==============================] - 0s 77ms/step - loss: 0.4530 - accuracy: 0.8354 - val_loss: 0.8017 - val_accuracy: 0.6500\n",
      "Epoch 19/40\n",
      "3/3 [==============================] - 0s 79ms/step - loss: 0.5283 - accuracy: 0.7848 - val_loss: 0.8940 - val_accuracy: 0.6500\n",
      "Epoch 20/40\n",
      "3/3 [==============================] - 0s 88ms/step - loss: 0.3119 - accuracy: 0.9114 - val_loss: 0.9157 - val_accuracy: 0.6500\n",
      "Epoch 21/40\n",
      "3/3 [==============================] - 0s 81ms/step - loss: 0.3267 - accuracy: 0.8861 - val_loss: 0.8270 - val_accuracy: 0.7000\n",
      "Epoch 22/40\n",
      "3/3 [==============================] - 0s 76ms/step - loss: 0.3864 - accuracy: 0.8228 - val_loss: 0.9476 - val_accuracy: 0.7000\n",
      "Epoch 23/40\n",
      "3/3 [==============================] - 0s 79ms/step - loss: 0.2738 - accuracy: 0.9114 - val_loss: 1.1449 - val_accuracy: 0.5500\n",
      "Epoch 24/40\n",
      "3/3 [==============================] - 0s 86ms/step - loss: 0.2812 - accuracy: 0.8987 - val_loss: 1.0507 - val_accuracy: 0.6000\n",
      "Epoch 25/40\n",
      "3/3 [==============================] - 0s 82ms/step - loss: 0.4672 - accuracy: 0.8608 - val_loss: 0.8921 - val_accuracy: 0.6000\n",
      "Epoch 26/40\n",
      "3/3 [==============================] - 0s 83ms/step - loss: 0.2971 - accuracy: 0.8987 - val_loss: 1.0380 - val_accuracy: 0.6000\n",
      "Epoch 27/40\n",
      "3/3 [==============================] - 0s 84ms/step - loss: 0.2991 - accuracy: 0.9241 - val_loss: 1.1310 - val_accuracy: 0.5000\n",
      "Epoch 28/40\n",
      "3/3 [==============================] - 0s 86ms/step - loss: 0.1702 - accuracy: 0.9620 - val_loss: 1.0120 - val_accuracy: 0.6000\n",
      "Epoch 29/40\n",
      "3/3 [==============================] - 0s 81ms/step - loss: 0.3479 - accuracy: 0.8734 - val_loss: 0.8903 - val_accuracy: 0.6500\n",
      "Epoch 30/40\n",
      "3/3 [==============================] - 0s 85ms/step - loss: 0.2552 - accuracy: 0.8987 - val_loss: 0.8979 - val_accuracy: 0.7000\n",
      "Epoch 31/40\n",
      "3/3 [==============================] - 0s 90ms/step - loss: 0.1307 - accuracy: 0.9747 - val_loss: 1.0589 - val_accuracy: 0.6500\n",
      "Epoch 32/40\n",
      "3/3 [==============================] - 0s 95ms/step - loss: 0.2675 - accuracy: 0.9114 - val_loss: 1.3117 - val_accuracy: 0.5500\n",
      "Epoch 33/40\n",
      "3/3 [==============================] - 0s 82ms/step - loss: 0.2766 - accuracy: 0.9494 - val_loss: 1.2642 - val_accuracy: 0.6500\n",
      "Epoch 34/40\n",
      "3/3 [==============================] - 0s 87ms/step - loss: 0.3260 - accuracy: 0.9241 - val_loss: 0.9445 - val_accuracy: 0.6000\n",
      "Epoch 35/40\n",
      "3/3 [==============================] - 0s 87ms/step - loss: 0.3511 - accuracy: 0.8987 - val_loss: 1.0165 - val_accuracy: 0.6500\n",
      "Epoch 36/40\n",
      "3/3 [==============================] - 0s 80ms/step - loss: 0.4289 - accuracy: 0.8608 - val_loss: 1.0167 - val_accuracy: 0.6500\n",
      "Epoch 37/40\n",
      "3/3 [==============================] - 0s 89ms/step - loss: 0.2962 - accuracy: 0.8734 - val_loss: 0.9421 - val_accuracy: 0.6500\n",
      "Epoch 38/40\n",
      "3/3 [==============================] - 0s 85ms/step - loss: 0.1959 - accuracy: 0.9367 - val_loss: 0.7466 - val_accuracy: 0.7000\n",
      "Epoch 39/40\n",
      "3/3 [==============================] - 0s 79ms/step - loss: 0.2251 - accuracy: 0.9494 - val_loss: 0.7648 - val_accuracy: 0.7500\n",
      "Epoch 40/40\n",
      "3/3 [==============================] - 0s 87ms/step - loss: 0.2693 - accuracy: 0.9241 - val_loss: 0.8668 - val_accuracy: 0.8000\n"
     ]
    }
   ],
   "source": [
    "#epoch is the number of times the neural network is trained with the whole dataset\n",
    "#in each epoch the dataset is divided into batches of size 32\n",
    "#we train the model with the training dataset divided and validate using validating dataset\n",
    "epochs = 40\n",
    "history = model.fit(X_train, y_train, batch_size=32, epochs=epochs, validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8cd2015d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 5 2 2 2 3 3 3 4 4 4 5 5 5]\n",
      "[1, 1, 1, 2, 2, 2, 3, 3, 3, 4, 4, 4, 5, 5, 5]\n",
      "0.9333333333333333\n"
     ]
    }
   ],
   "source": [
    "#testing accuracy on test dataset\n",
    "data = []\n",
    "labels = []\n",
    "classes = 5\n",
    "cur_path = os.getcwd()\n",
    "\n",
    "#there are 43 kinds of traffic sign boards in the dataset, hence the no. of of classes is taken as 43.\n",
    "#Retrieving the images and their labels\n",
    "for i in range(classes):\n",
    "    path = os.path.join(cur_path,'test_own',str(i+1))\n",
    "    images = os.listdir(path)\n",
    "\n",
    "    #we open each folder and extract the images and store in the list data[]\n",
    "    for a in images:\n",
    "        try:\n",
    "            image = Image.open(path + '\\\\'+ a)\n",
    "            image = image.resize((30,30))\n",
    "            image = np.array(image)\n",
    "            #sim = Image.fromarray(image)\n",
    "            data.append(image)\n",
    "            labels.append(i+1)\n",
    "        except:\n",
    "            print(\"Error loading image\")\n",
    "\n",
    "\n",
    "\n",
    "#we access all the test images from each folder in test dataset and convert it into numpy array    \n",
    "X_test=np.array(data)\n",
    "\n",
    "predict_x=model.predict(X_test)       #predicted values\n",
    "classes_x=np.argmax(predict_x,axis=1) #Actual values\n",
    "print(classes_x)\n",
    "print(labels)\n",
    "\n",
    "#pred = model.predict_classes(X_test)\n",
    "\n",
    "#Accuracy with the test data\n",
    "from sklearn.metrics import accuracy_score\n",
    "print(accuracy_score(labels, classes_x)) \n",
    "#Then we check the accuracy of our classification model which is 96%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b36b74a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('tsr_own.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6f66cca8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2 0 0 0 0]\n",
      " [0 3 0 0 0]\n",
      " [0 0 3 0 0]\n",
      " [0 0 0 3 0]\n",
      " [1 0 0 0 3]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "#Generate the confusion matrix\n",
    "cf_matrix = confusion_matrix(classes_x, labels)\n",
    "\n",
    "print(cf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "01221e92",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "ax = sns.heatmap(cf_matrix,annot=True,cmap='Blues')\n",
    "\n",
    "ax.set_title('Seaborn Confusion Matrix with labels\\n\\n');\n",
    "ax.set_xlabel('\\nPredicted Values')\n",
    "ax.set_ylabel('Actual Values ');\n",
    "\n",
    "## Display the visualization of the Confusion Matrix.\n",
    "#Dark colour indicates more predictions for those values\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e25ba8b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TPR = 0.9333333333333333\n",
      "TNR = 0.9833333333333333\n",
      "FPR = 0.016666666666666666\n",
      "FNR = 0.06666666666666667\n",
      "Accuracy = 0.9733333333333334\n"
     ]
    }
   ],
   "source": [
    "FP = cf_matrix.sum(axis=0) - np.diag(cf_matrix)  \n",
    "FN = cf_matrix.sum(axis=1) - np.diag(cf_matrix)\n",
    "TP = np.diag(cf_matrix)\n",
    "TN = cf_matrix.sum() - (FP + FN + TP)\n",
    "FP = FP.sum()\n",
    "FN = FN.sum()\n",
    "TP = TP.sum()\n",
    "TN = TN.sum()\n",
    "TPR = TP/(TP+FN)\n",
    "TNR = TN/(TN+FP) \n",
    "FPR = FP/(FP+TN)\n",
    "FNR = FN/(TP+FN)\n",
    "ACC = (TP+TN)/(TP+FP+FN+TN)\n",
    "print(\"TPR =\",TPR)\n",
    "print(\"TNR =\",TNR)\n",
    "print(\"FPR =\",FPR)\n",
    "print(\"FNR =\",FNR)\n",
    "print(\"Accuracy =\",ACC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68fbd304",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
